# 빅데이터 관련 소프트웨어 정리

## 1. 빅데이터 플랫폼 구축 소프트웨어

| 소프트웨어  |       핵심        | 목적                                                         |
| :---------: | :---------------: | :----------------------------------------------------------- |
|      R      |   빅데이터 분석   | * 통계 프로그래밍 언어인 S 언어를 기반으로 만들어진 오픈소스 프로그래밍 언어<br />* 다양한 그래프 패키지들을 통하여 강력한 시각화 기능 제공 |
| 우지(Oozie) |  워크플로우 관리  | * 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템(스케줄링/모니터링)<br />* 맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어 |
| 플럼(Flume) |    데이터 수집    | * 이벤트(Event)와 에이전트(Agent)를 활용하여 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동 |
|    HBase    | 분산 데이터베이스 | * 컬럼 기반 저장소로 HDFS와 인터페이스 제공                  |
| 스쿱(Sqoop) |  정형데이터 수집  | * 'SQL to Hadoop'의 약자<br />* 커넥터(Connector)를 사용하여 관계형 데이터베이스(RDBMS)에서 하둡 파일 시스템(HDFS)으로 데이터를 수집하거나, 하둡 파일 시스템에서 관계형 데이터베이스로 데이터를 보내는 기능 수행 |



## 2. 분산 컴퓨팅 환경 소프트웨어 구성요소

|            구분             | 주요 특징                                                    |
| :-------------------------: | :----------------------------------------------------------- |
|    맵 리듀스(Map Reduce)    | * Key-Value 형태의 데이터 처리<br />* 맵(Map) -> 셔플(Shuffle) -> 리듀스(Reduce) 순서대로 데이터 처리<br />* Map: Key - Value 형태로 데이터를 취합<br />* Shuffle: 데이터를 통합하여 처리<br />* 리듀스: 맵 처리된 데이터를 정리 |
|          얀(YARN)           | * 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 처리 플랫폼<br />* 리소스 매니저(Master)와 노드 매니저(Slave)로 구성<br />* 리소스 매니저: 스키줄러 역할을 수행하고 클러스터 이용률 최적화를 수행<br />* 노드 매니저: 노드 내의 자원을 관리하고 리소스 매니저에게 전달 수행 및 컨테이너를 관리<br />* 애플리케이션 마스터: 리소스 매니저와 자원의 교섭을 책임지고, 컨테이너를 실행<br />* 컨테이너: 프로그램 구동을 위한 격리 환경을 지원하는 가상화 자원 |
| 아파치 스파크(Apache Spark) | * 하둡 기반 대규모 데이터 분산처리시스템<br />* 스트리밍 데이터, 온라인 머신러닝 등 실시간 데이터 처리<br />* 스칼라, 자바, 파이썬, R 등 사용 가능 |
| 하둡 분산 파일 시스템(HDFS) | * Hadoop Distributed File System의 약자<br />* 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템<br />* 네임 노드(Master)와 데이터 노드(Slave)로 구성<br />* 네임 노드: 파일 이름, 권한 등의 속성 기록<br />* 데이터 노드: 일정한 크기로 나눈 블록 형태로 저장 |
| 아파치 하둡(Apache Hadoop)  | * 분산 파일 시스템(HDFS)과 맵리듀스를 중심으로 다양한 프로그램으로 구성된 하둡 에코시스템을 가짐<br />* 클라우드 플랫폼 위에서 클러스터를 구성해 데이터 분석 |



## 3. 하둡 에코시스템(Hadoop Ecosystem)

* 하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임
* 하둡 에코시스템은 수집, 저장, 처리 기술과 분석, 실시간 및 시각화를 위한 기술로 구분할 수 있다.

### - 하둡 에코시스템의 수집 기술

|        구분        |        기술        | 설명                                                         |
| :----------------: | :----------------: | :----------------------------------------------------------- |
| 비정형 데이터 수집 |   척와(Chuckwa)    | * 분산된 각 서버에서 에이전트를 실행하고, 컬렉터가 각 에이전트로부터 데이터를 받아 HDFS에 저장 |
| 비정형 데이터 수집 |    플럼(Flume)     | * 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트를 활용하는 기술 |
| 비정형 데이터 수집 | 스크라이브(Scribe) | * 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술<br />* 최종 데이터는 HDFS 외에 다양한 저장소를 활용 가능<br />* HDFS에 저장하기 위해서는 `JNI`를 이용 |
|  정형 데이터 수집  |    스쿱(Sqoop)     | * 대용량 데이터 전송 솔루션<br />* 커넥터를 사용하여 관계형 데이터베이스 시스템에서 하둡 파일 시스템으로 데이터를 수집하거나, 하둡 파일 시스템에서 간계형 데이터베이스로 데이터를 보내는 기능 수행<br />* Oracle, MS-SQL, DB2와 같은 상용 RDBMS와 MysQL과 같은 오픈 소스 RDBMS 지원 |
|  정형 데이터 수집  |     히호(Hiho)     | * 스쿱과 같은 대용량 데이터 전송 솔루션이며, 현재 깃허브에 공개되어 있음<br />* 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원, 현재는 Oracle, MySQL의 데이터만 전송 지원 |

> JNI(Java Native Interface): 자바 가상 머신(JVM) 위에서 실행 되고 있는 자바 코드가 네이티브 응용 프로그램 그리고 C, C++, 어셈블리 같은 다른 언어들로 작성된 라이브러리들을 호출하거나 반대로 호출되는 것을 가능하게 하는 프로그래밍 프레임워크

### - 하둡 에코시스템의 데이터 저장 및 처리 기술

|       구분       |         기술         | 설명                                                         |
| :--------------: | :------------------: | ------------------------------------------------------------ |
| 분산 데이터 저장 |         HDFS         | * 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템<br />* 범용 하드웨어 기반, 클러스터에서 실행되고 데이터 접근 패턴을 스트리밍 방식으로 지원<br />* 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동복구 특징이 있음 |
| 분산 데이터 처리 | 맵리듀스(Map Reduce) | * 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위한 목적으로 만들어진 소프트웨어 프레임워크<br />* 모든 데이터를 키-값(Key-Value) 쌍으로 구성, 데이터를 분류 |
| 분산 데이터 처리 |        HBase         | * 컬럼 기반 저장소로 HDFS와 인터페이스 제공<br />* 실시간 랜덤 조회 및 업데이트를 할 수 있으며, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있음 |



### - 하둡 에코시스템의 데이터 가공 및 분석 관리를 위한 주요 기술

|      구분       |       기술        | 설명                                                         |
| :-------------: | :---------------: | ------------------------------------------------------------ |
|   데이터 가공   |     피그(Pig)     | * 대용량 데이터 집합을 분석하기 위한 플랫폼으로 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 `피그 라틴`이라는 자체 언어를 제공<br />* 맵리듀스 API를 매우 단순화시키고, SQL과 유사한 형태로 설계됨<br />* SQL과 유사하기만 할 뿐, 기존 SQL 지식을 활용하는 것이 어려움 |
|   데이터 가공   |   하이브(Hive)    | * 하둡 기반의 `DW` 솔루션<br />* SQL과 매우 유사한 HiveQL이라는 쿼리를 제공<br />* HiveQL은 내부적으로 맵리듀스로 변환되어 실행됨 |
|  데이터마이닝   |  머하웃(Mahout)   | * 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스<br />* 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘 지원 |
| 실시간 SQL 쿼리 |  임팔라(Impala)   | * 하둡 기반의 실시간 SQL 쿼리 시스템<br />* 데이터 조회를 위한 인터페이스로 HiveQL을 사용<br />* 수초 내에 SQL 쿼리 결과를 확인할 수 있으며, HBase와 연동이 가능 |
| 워크플로우 관리 |    우지(Oozie)    | * 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템<br />* 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버<br />* 맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어 |
| 분산 코디네이션 | 주키퍼(Zookeeper) | * 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공<br />* 하나의 서버에만 서비스가 집중되지 않도록 서비스를 알맞게 분산하여 동시에 처리<br />* 하나의 서버에서 처리한 결과를 다른 서버들과도 동기화하여 데이터의 안전성을 보장 |

> DW(Data Warehouse): 사용자의 의사 결정에 도움을 주기 위하여, 기간 시스템의 데이터베이스에 축적된 데이터를 공통 형식으로 변환해서 관리하는 데이터베이스
> 